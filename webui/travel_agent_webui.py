'''
Author: vinjinwang vinjinwang@tencent.com
Date: 2025-11-02
Description: Gradio Web UI for Travel Agent with Thought-Action-Observation Loop
'''
import os
import re
import gradio as gr
from dotenv import load_dotenv
from typing import List, Dict, Any, Tuple

from models.openai_client import OpenAICompatibleClient
from prompts.travel_prompt import AGENT_SYSTEM_PROMPT
from tools.available_tools import available_tools

load_dotenv()

class TravelAgent:
    """Travel Agent with Thought-Action-Observation Loop"""
    
    def __init__(self):
        # Configure LLM client
        self.API_KEY = os.getenv("OPENAI_API_KEY")
        self.BASE_URL = "http://one-api.woa.com/v1"
        self.MODEL_ID = "gpt-4o"
        
        self.llm = OpenAICompatibleClient(
            model=self.MODEL_ID,
            api_key=self.API_KEY,
            base_url=self.BASE_URL
        )
    
    def process_query(self, user_query: str, max_iterations: int = 5) -> Tuple[str, List[Dict[str, Any]]]:
        """
        Process user query through thought-action-observation loop
        
        Returns:
            Tuple of (final_answer, thinking_process)
        """
        if not user_query.strip():
            return "è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢å†…å®¹ã€‚", []
        
        prompt_history = [f"ç”¨æˆ·è¯·æ±‚: {user_query}"]
        thinking_process = []
        
        for i in range(max_iterations):
            # Build full prompt
            full_prompt = "\n".join(prompt_history)
            
            # Call LLM for thinking
            llm_output = self.llm.generate(full_prompt, system_prompt=AGENT_SYSTEM_PROMPT)
            
            # Parse thought and action
            thought_match = re.search(r"Thought: (.*?)(?=Action:|$)", llm_output, re.DOTALL)
            action_match = re.search(r"Action: (.*)", llm_output, re.DOTALL)
            
            thought = thought_match.group(1).strip() if thought_match else "æœªæ‰¾åˆ°æ€è€ƒå†…å®¹"
            
            if not action_match:
                thinking_process.append({
                    "iteration": i + 1,
                    "thought": thought,
                    "action": "è§£æé”™è¯¯ï¼šæœªæ‰¾åˆ°Action",
                    "observation": "æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯"
                })
                return "è§£æé”™è¯¯ï¼šæ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° Actionã€‚", thinking_process
            
            action_str = action_match.group(1).strip()
            
            # Check if task is finished
            if action_str.startswith("finish"):
                final_answer_match = re.search(r'finish\(answer="(.*)"\)', action_str)
                if final_answer_match:
                    final_answer = final_answer_match.group(1)
                    thinking_process.append({
                        "iteration": i + 1,
                        "thought": thought,
                        "action": action_str,
                        "observation": "ä»»åŠ¡å®Œæˆ"
                    })
                    return final_answer, thinking_process
                else:
                    return "è§£æé”™è¯¯ï¼šæ— æ³•æå–æœ€ç»ˆç­”æ¡ˆã€‚", thinking_process
            
            # Parse and execute tool
            try:
                tool_name = re.search(r"(\w+)\(", action_str).group(1)
                args_str = re.search(r"\((.*)\)", action_str).group(1)
                kwargs = dict(re.findall(r'(\w+)="([^"]*)"', args_str))
                
                if tool_name in available_tools:
                    observation = available_tools[tool_name](**kwargs)
                else:
                    observation = f"é”™è¯¯ï¼šæœªå®šä¹‰çš„å·¥å…· '{tool_name}'"
                
            except Exception as e:
                observation = f"é”™è¯¯ï¼šè§£ææˆ–æ‰§è¡Œå·¥å…·æ—¶å‡ºé”™ - {e}"
            
            # Record thinking process
            thinking_process.append({
                "iteration": i + 1,
                "thought": thought,
                "action": action_str,
                "observation": observation
            })
            
            # Add to prompt history
            prompt_history.append(llm_output)
            observation_str = f"Observation: {observation}"
            prompt_history.append(observation_str)
        
        return "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä»»åŠ¡æœªå®Œæˆã€‚", thinking_process

def format_thinking_process(thinking_process: List[Dict[str, Any]]) -> str:
    """Format thinking process for display"""
    if not thinking_process:
        return "æš‚æ— æ€è€ƒè¿‡ç¨‹"
    
    formatted = []
    for step in thinking_process:
        formatted.append(f"""
**ç¬¬ {step['iteration']} è½®æ€è€ƒ**

ğŸ¤” **æ€è€ƒè¿‡ç¨‹ï¼š**
{step['thought']}

ğŸ”§ **æ‰§è¡ŒåŠ¨ä½œï¼š**
{step['action']}

ğŸ‘ï¸ **è§‚å¯Ÿç»“æœï¼š**
{step['observation']}

---
""")
    
    return "\n".join(formatted)

def chat_interface(message: str, history: List[List[str]]) -> Tuple[str, List[List[str]], str]:
    """
    Gradio chat interface function
    
    Returns:
        Tuple of (response, updated_history, thinking_process_display)
    """
    if not message.strip():
        return "", history, "è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢å†…å®¹ã€‚"
    
    # Initialize agent
    agent = TravelAgent()
    
    # Process the query
    final_answer, thinking_process = agent.process_query(message)
    
    # Format thinking process for display
    thinking_display = format_thinking_process(thinking_process)
    
    # Update chat history
    history.append([message, final_answer])
    
    return "", history, thinking_display

def create_interface():
    """Create and configure Gradio interface"""
    
    with gr.Blocks(
        title="æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹",
        theme=gr.themes.Soft(),
        css="""
        .thinking-process {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 10px 0;
        }
        """
    ) as demo:
        
        gr.Markdown("""
        # ğŸŒ æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹
        
        æ¬¢è¿ä½¿ç”¨æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ï¼æˆ‘å¯ä»¥å¸®æ‚¨æŸ¥è¯¢å¤©æ°”ä¿¡æ¯å¹¶æ¨èåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚
        
        **åŠŸèƒ½ç‰¹ç‚¹ï¼š**
        - ğŸŒ¤ï¸ å®æ—¶å¤©æ°”æŸ¥è¯¢
        - ğŸ›ï¸ æ™ºèƒ½æ™¯ç‚¹æ¨è
        - ğŸ§  é€æ˜çš„æ€è€ƒè¿‡ç¨‹å±•ç¤º
        
        **ä½¿ç”¨ç¤ºä¾‹ï¼š**
        - "è¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚"
        - "æˆ‘æƒ³å»ä¸Šæµ·æ—…æ¸¸ï¼Œè¯·å…ˆæŸ¥çœ‹å¤©æ°”æƒ…å†µå†ç»™æˆ‘æ¨èæ™¯ç‚¹ã€‚"
        """)
        
        with gr.Row():
            with gr.Column(scale=2):
                # Chat interface
                chatbot = gr.Chatbot(
                    label="å¯¹è¯è®°å½•",
                    height=400,
                    show_label=True,
                    container=True,
                    type="tuples"
                )
                
                with gr.Row():
                    msg_input = gr.Textbox(
                        placeholder="è¯·è¾“å…¥æ‚¨çš„æ—…è¡ŒæŸ¥è¯¢...",
                        label="è¾“å…¥æ¶ˆæ¯",
                        lines=2,
                        max_lines=5,
                        show_label=False,
                        container=False,
                        scale=4
                    )
                    send_btn = gr.Button("å‘é€", variant="primary", scale=1)
                
                # Clear button
                clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary")
            
            with gr.Column(scale=1):
                # Thinking process display
                thinking_display = gr.Markdown(
                    label="ğŸ§  æ™ºèƒ½ä½“æ€è€ƒè¿‡ç¨‹",
                    value="ç­‰å¾…æ‚¨çš„æŸ¥è¯¢...",
                    elem_classes=["thinking-process"],
                    height=500
                )
        
        # Event handlers
        def submit_message(message, history):
            return chat_interface(message, history)
        
        def clear_chat():
            return [], "ç­‰å¾…æ‚¨çš„æŸ¥è¯¢..."
        
        # Bind events
        send_btn.click(
            submit_message,
            inputs=[msg_input, chatbot],
            outputs=[msg_input, chatbot, thinking_display]
        )
        
        msg_input.submit(
            submit_message,
            inputs=[msg_input, chatbot],
            outputs=[msg_input, chatbot, thinking_display]
        )
        
        clear_btn.click(
            clear_chat,
            outputs=[chatbot, thinking_display]
        )
        
        # Example queries
        gr.Examples(
            examples=[
                ["è¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚"],
                ["æˆ‘æƒ³å»ä¸Šæµ·æ—…æ¸¸ï¼Œè¯·å…ˆæŸ¥çœ‹å¤©æ°”æƒ…å†µå†ç»™æˆ‘æ¨èæ™¯ç‚¹ã€‚"],
                ["æŸ¥è¯¢å¹¿å·çš„å¤©æ°”ï¼Œå¹¶æ¨èé€‚åˆå½“å‰å¤©æ°”çš„æˆ·å¤–æ´»åŠ¨åœºæ‰€ã€‚"],
                ["å¸®æˆ‘çœ‹çœ‹æ·±åœ³ä»Šå¤©çš„å¤©æ°”å¦‚ä½•ï¼Œæ¨èä¸€äº›é€‚åˆçš„æ—…æ¸¸åœ°ç‚¹ã€‚"]
            ],
            inputs=msg_input,
            label="ç¤ºä¾‹æŸ¥è¯¢"
        )
        
        gr.Markdown("""
        ---
        
        **æ³¨æ„äº‹é¡¹ï¼š**
        - è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®ç¯å¢ƒå˜é‡ `OPENAI_API_KEY` å’Œ `TAVILY_API_KEY`
        - å¤©æ°”æŸ¥è¯¢ä½¿ç”¨ wttr.in APIï¼Œæ™¯ç‚¹æ¨èä½¿ç”¨ Tavily Search API
        - å³ä¾§é¢æ¿ä¼šå®æ—¶æ˜¾ç¤ºæ™ºèƒ½ä½“çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ¯ä¸€è½®çš„æ€è€ƒã€è¡ŒåŠ¨å’Œè§‚å¯Ÿç»“æœ
        """)
    
    return demo

if __name__ == "__main__":
    # Create and launch the interface
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )